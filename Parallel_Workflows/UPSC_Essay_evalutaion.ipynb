{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23603b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3400530",
   "metadata": {},
   "source": [
    "I am use open source Model because chat gpt is very costly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d82e9",
   "metadata": {},
   "source": [
    "HuggingFace-Model-Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901d1429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370a279a2bba416b93654f747fe75c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74bb1f932b046acba445591e8c5d5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e306ce45dd2441e4bfde7643e72bc4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b0e64fcb54f549def36f6b4e0368e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b4256edd16491f967700271b980d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388c08a5c137416f87424a3dfd5e05de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef275a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict,Annotated\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel,Field\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9108892",
   "metadata": {},
   "source": [
    "Define Schema to get outoput from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d27eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationSchema(BaseModel):\n",
    "    feedback: str = Field(description=\"Detailed feedback on the essay\")\n",
    "    score: int = Field(description=\"Score out of 10 \", ge=0, le=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670629ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "parser = PydanticOutputParser(pydantic_object=EvaluationSchema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0bafd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt=PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    you are an expert essay evaluator.\n",
    "\n",
    "    Evaluate the following essay and provide detailed feedback along with a score out of 10.\n",
    "    Essay:\n",
    "    {essay}\n",
    "    \n",
    "    Provide your response in the following format:\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "        input_variables=[\"essay\"],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284fdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL chain\n",
    "evaluation_chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "871e981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_text = \"\"\"India in the Age of AI\n",
    "As the world enters a transformative era defined by artificial intelligence (AI), India stands at a critical juncture — one where it can either emerge as a global leader in AI innovation or risk falling behind in the technology race. The age of AI brings with it immense promise as well as unprecedented challenges, and how India navigates this landscape will shape its socio-economic and geopolitical future.\n",
    "\n",
    "India's strengths in the AI domain are rooted in its vast pool of skilled engineers, a thriving IT industry, and a growing startup ecosystem. With over 5 million STEM graduates annually and a burgeoning base of AI researchers, India possesses the intellectual capital required to build cutting-edge AI systems. Institutions like IITs, IIITs, and IISc have begun fostering AI research, while private players such as TCS, Infosys, and Wipro are integrating AI into their global services. In 2020, the government launched the National AI Strategy (AI for All) with a focus on inclusive growth, aiming to leverage AI in healthcare, agriculture, education, and smart mobility.\n",
    "\n",
    "One of the most promising applications of AI in India lies in agriculture, where predictive analytics can guide farmers on optimal sowing times, weather forecasts, and pest control. In healthcare, AI-powered diagnostics can help address India’s doctor-patient ratio crisis, particularly in rural areas. Educational platforms are increasingly using AI to personalize learning paths, while smart governance tools are helping improve public service delivery and fraud detection.\n",
    "\n",
    "However, the path to AI-led growth is riddled with challenges. Chief among them is the digital divide. While metropolitan cities may embrace AI-driven solutions, rural India continues to struggle with basic internet access and digital literacy. The risk of job displacement due to automation also looms large, especially for low-skilled workers. Without effective skilling and re-skilling programs, AI could exacerbate existing socio-economic inequalities.\n",
    "\n",
    "Another pressing concern is data privacy and ethics. As AI systems rely heavily on vast datasets, ensuring that personal data is used transparently and responsibly becomes vital. India is still shaping its data protection laws, and in the absence of a strong regulatory framework, AI systems may risk misuse or bias.\n",
    "\n",
    "To harness AI responsibly, India must adopt a multi-stakeholder approach involving the government, academia, industry, and civil society. Policies should promote open datasets, encourage responsible innovation, and ensure ethical AI practices. There is also a need for international collaboration, particularly with countries leading in AI research, to gain strategic advantage and ensure interoperability in global systems.\n",
    "\n",
    "India’s demographic dividend, when paired with responsible AI adoption, can unlock massive economic growth, improve governance, and uplift marginalized communities. But this vision will only materialize if AI is seen not merely as a tool for automation, but as an enabler of human-centered development.\n",
    "\n",
    "In conclusion, India in the age of AI is a story in the making — one of opportunity, responsibility, and transformation. The decisions we make today will not just determine India’s AI trajectory, but also its future as an inclusive, equitable, and innovation-driven society.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91119282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "evaluation = evaluation_chain.invoke({\n",
    "    \"essay\": essay_text\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856a959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
